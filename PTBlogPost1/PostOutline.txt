
----------Topics----------

Maybe don't number the posts, but link to them from eachother and have an order that way? add a new category for path tracing?

+ Intro:
 * Start with images of scene2 and scene3 (yes with cosine and AA)
 * explain path tracing high level
 * show a version with only 1 bounce as comparison next to one with 5 bounces. highlight soft shadows, color bleed, global illumination, ambient occlusion
 * show scene2 and scene3 without cosine and aa?
 * explain that focus is on practical, not formal.  Link to formal explanations
 * explain how path tracing helps teach about physically based rendering etc, so you understand the things that real time algorithms try to approximate

+ rendering equation

+ get Jay's link to cosine law and put it on post!

+ Explain the rendering equation
+ Explain the algorithm at a high level

+ how to make camera rays
+ mention having to push the ray out a little bit. could also use unique ID per object and ignore that id, but there are problems when you are inside an object, or dealing with transparents.

+ explain that we are just doing diffuse and emissive lighting right now.
 * mention lambertian surface (diffuse reflection only, equal in all directions)
 * mention that reflection and refraction are two other important features that we will be adding later

+ mention that this is "naive" path tracing. Lots of other features possible, and getting better images faster.

+ Debugging: visualize things per pixel
 * show debug images of normals and bounce count

+ mention furnace test as a quick way to debug? actually doesn't seem super useful, maybe not...
 * nah

+ put these in the practical section?
 * talk about gamma correction (and link to page talking about it)
 * talk about HDR and that we are just clamping, but later could use tone mapping (link to a tone mapping post?)

+ random point on sphere
 * http://mathworld.wolfram.com/SpherePointPicking.html

+ link to smallpt as a 99 lines of code path tracer - if code brevity helps understanding.

+ primitive types and count matters!
 * perf of Scene 3 512x512 with 5 bounces and 100 spp . "on my machine" don't need to give specs
 * 30 Triangles:    12.1 seconds
 * 15 Quads:         6.2 seconds -> makes sense. half the primitives, and quads are basically same cost as triangles due to how it tests
 * 5 quads, 2 obbs:  5.5 seconds

+ thank lauren for help isolating where noise was coming from
 * also nathan reed

+ could mention that we could cache first hit of screen ray since it will always be the same
 * not useful with how we will do AA in a future post, but could save quite a bit of time
 ? should you code this as an option in the code, and report timings?

+ grab quote on twitter from morgan mcguire "a minute to learn, a lifetime to master"
 * make it a clickable link? https://twitter.com/CasualEffects/status/771536715777400832

+ need to mention that the example images use both AA and cosine sampling, so look nicer than what the code for this post will make, but we'll cover those topics next.

+ talk about the fact that it's very multithreading friendly
 * and that it runs a lot faster on GPU

+ mention rendering with 8 threads?

128x128
5 bounces
Scene0
 - 10spp = 0.0 seconds
 - 100spp = 0.1 seconds
 - 1000spp = 1.0 seconds
 - 10000spp = 9.3 seconds
 - 100000spp = 89.0 seconds
Scene1
 - 10 = 0.0s
 - 100 = 0.1s
 - 1k = 1.0s
 - 10k = 9.1s
 - 100k = 89.2s
scene2
 - 10 = 0.1s
 - 100 = 0.5s
 - 1k = 3.7s
 - 10k = 34.7s
 - 100k = 341.4s (5.7 minutes)
scene3
 - 10 = 0.1s
 - 100 = 0.4s
 - 1k = 3.5s
 - 10k = 32.5s
 - 100k = 326.2s (5.4 minutes)

+ Show images of each scene with varying # of samples and how long it took to render them
 * maybe also vary # of bounces and show how long it took to render them
 * also image size
 * explain how rendering parameters affect rendering time
 * maybe also how 4x samples = 50% error
 * could explain that with coin toss thing: http://groups.csail.mit.edu/graphics/classes/6.837/F04/lectures/14_Sampling-used6.pdf (page 7)

+ slow convergence discussion:
 * http://computergraphics.stackexchange.com/questions/3972/is-it-expected-that-a-naive-path-tracer-takes-many-many-samples-to-converge/3976#3976
 * the more different that samples are, the longer it will take to converge (could make an example of that if you care to?)



- link to source code -> github (gist? or repo?) and zip file?

- make sure you didn't miss anything important from the other blog post you were working on.

- make sure all TODO's are done in the post!!

===== NOT DOING =====

- Semi formal intro
 * like what is already there "What is Path Tracing" - or "rendering equation" explanation?
 * how to make camera rays
 * what happens to a ray when it hits a surface

- "Now that we know how to get the ray for a pixel, we need to figure out what objects our ray hits."
 * mention that we are going to use analytical tests. ray vs object type.
 * could mention that there is a technical called ray marching (or sphere tracing) which lets you intersect rays with shapes where you only know how to say if a point is inside or outside.
 * link to a ray marching link?

- "The second step is where our path bounces and becomes recursive. We have to limit the number of bounces to some amount. Limiting to say 5 bounces is a fairly sane value for simple scenes like our sample scene. You may want a larger number of bounces for more complex scenes."
 * above that, could highlight the relevant part from the rendering equation. or maybe color code it into part 1 and part 2? 

+ divide by pi or not
 * https://seblagarde.wordpress.com/2012/01/08/pi-or-not-to-pi-in-game-lighting-equation/
 * more here: https://seblagarde.wordpress.com/2011/08/17/hello-world/
 * and wikipedia (which does): https://en.wikipedia.org/wiki/Path_tracing
